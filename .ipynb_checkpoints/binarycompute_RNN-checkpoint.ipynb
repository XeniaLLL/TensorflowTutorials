{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 血淋淋的教训是记住权值更新w+=！！！\n",
    "#Reference: https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/\n",
    "#https://blog.csdn.net/weiwei9363/article/details/78902455（解读）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# compute sigmoid nonlinearity\n",
    "def sigmoid(x):\n",
    "    output = 1/(1+np.exp(-x))\n",
    "    return output\n",
    "\n",
    "# convert output of sigmoid function to its derivative\n",
    "def sigmoid_output_to_derivative(output):\n",
    "    return output*(1-output)\n",
    "\n",
    "\n",
    "# training dataset generation\n",
    "int2binary = {}\n",
    "binary_dim = 8\n",
    "\n",
    "largest_number = pow(2,binary_dim)\n",
    "binary = np.unpackbits(\n",
    "    np.array([range(largest_number)],dtype=np.uint8).T,axis=1)\n",
    "for i in range(largest_number):\n",
    "    int2binary[i] = binary[i]\n",
    "\n",
    "# input variables\n",
    "alpha = 0.1\n",
    "n_input = 2\n",
    "n_hidden= 16\n",
    "n_output = 1\n",
    "\n",
    "\n",
    "# initialize neural network weights\n",
    "#使用2为输入维度\n",
    "#random.random生成数是【0，1），进而保证w在【-1，1）\n",
    "w1 = 2*np.random.random((n_input,n_hidden)) - 1\n",
    "w2 = 2*np.random.random((n_hidden,n_output)) - 1\n",
    "wh = 2*np.random.random((n_hidden,n_hidden)) - 1\n",
    "\n",
    "w_update1 = np.zeros_like(w1)\n",
    "w_update2 = np.zeros_like(w2)\n",
    "w_updateh = np.zeros_like(wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:[3.45638663]\n",
      "Pred:[0 0 0 0 0 0 0 1]\n",
      "True:[0 1 0 0 0 1 0 1]\n",
      "9+60=1\n",
      "---------------------------------------------\n",
      "Error:[3.63389116]\n",
      "Pred:[1 1 1 1 1 1 1 1]\n",
      "True:[0 0 1 1 1 1 1 1]\n",
      "28+35=255\n",
      "---------------------------------------------\n",
      "Error:[3.91366595]\n",
      "Pred:[0 1 0 0 1 0 0 0]\n",
      "True:[1 0 1 0 0 0 0 0]\n",
      "116+44=72\n",
      "---------------------------------------------\n",
      "Error:[3.72191702]\n",
      "Pred:[1 1 0 1 1 1 1 1]\n",
      "True:[0 1 0 0 1 1 0 1]\n",
      "4+73=223\n",
      "---------------------------------------------\n",
      "Error:[3.5852713]\n",
      "Pred:[0 0 0 0 1 0 0 0]\n",
      "True:[0 1 0 1 0 0 1 0]\n",
      "71+11=8\n",
      "---------------------------------------------\n",
      "Error:[2.53352328]\n",
      "Pred:[1 0 1 0 0 0 1 0]\n",
      "True:[1 1 0 0 0 0 1 0]\n",
      "81+113=162\n",
      "---------------------------------------------\n",
      "Error:[0.57691441]\n",
      "Pred:[0 1 0 1 0 0 0 1]\n",
      "True:[0 1 0 1 0 0 0 1]\n",
      "81+0=81\n",
      "---------------------------------------------\n",
      "Error:[1.42589952]\n",
      "Pred:[1 0 0 0 0 0 0 1]\n",
      "True:[1 0 0 0 0 0 0 1]\n",
      "4+125=129\n",
      "---------------------------------------------\n",
      "Error:[0.47477457]\n",
      "Pred:[0 0 1 1 1 0 0 0]\n",
      "True:[0 0 1 1 1 0 0 0]\n",
      "39+17=56\n",
      "---------------------------------------------\n",
      "Error:[0.21595037]\n",
      "Pred:[0 0 0 0 1 1 1 0]\n",
      "True:[0 0 0 0 1 1 1 0]\n",
      "11+3=14\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for j in range(10000):#训练次数\n",
    "    \n",
    "    #generate a simple addtion problem(a+b=c???)\n",
    "    #除以2为了相加的值小于等于256\n",
    "    a_int=np.random.randint(largest_number/2)#int version\n",
    "    a=int2binary[a_int]#binary coding\n",
    "\n",
    "    b_int=np.random.randint(largest_number/2)#int version\n",
    "    b=int2binary[b_int]#binary coding\n",
    "    \n",
    "    c_int=a_int+b_int\n",
    "    c=int2binary[c_int]\n",
    "    \n",
    "    #where to store the best guess\n",
    "    d=np.zeros_like(c)\n",
    "    \n",
    "    overallError=0#每次训练之后把总误差清零，用来记录下一次训练的情况\n",
    "\n",
    "    layer_2_deltas=list()\n",
    "    layer_1_values=list()\n",
    "    layer_1_values.append(np.zeros(n_hidden))\n",
    "#     print(j,\": \",wh[1])\n",
    "    \n",
    "    #moving along the positions int the binary encoding\n",
    "    for position in range(binary_dim):\n",
    "       \n",
    "        X=np.array([[a[binary_dim-position-1],b[binary_dim-position-1]]])\n",
    "        \n",
    "        Y=np.array([[c[binary_dim-position-1]]]).T\n",
    "\n",
    "        #print(layer_1_values[-1])#负数表示倒数第几个数，\n",
    "        #至于为什么是0.，0和0. 0还需要继续思考：我现在的想法是为了取上一次的layer1的值\n",
    "        #hidden_layer( input +prev_hidden)\n",
    "        layer_1=sigmoid(np.dot(X,w1)+np.dot(layer_1_values[-1],wh))\n",
    "        #加的是之前的s3\n",
    "        \n",
    "        #output layer(new binary representation\n",
    "        layer_2=sigmoid(np.dot(layer_1,w2))\n",
    " \n",
    "        layer_2_error=Y-layer_2     \n",
    "   \n",
    "        layer_2_deltas.append((layer_2_error)*sigmoid_output_to_derivative(layer_2))\n",
    "        #print (layer_2_deltas)\n",
    "        overallError+=np.abs(layer_2_error[0])\n",
    "        \n",
    "        #decode estimate so we can print it out,\n",
    "        #         返回四舍五入之后的值，所以之后要么是1要么是0\n",
    "        #d装的是某个位置的值，也就是训练之后的值\n",
    "\n",
    "        d[binary_dim - position - 1]=np.round(layer_2[0][0])\n",
    "    \n",
    "        # store hidden layer so we can use it in the next timestep\n",
    "        layer_1_values.append(copy.deepcopy(layer_1))\n",
    "    future_layer_1_delta=np.zeros(n_hidden)\n",
    "\n",
    "    for position in range(binary_dim):\n",
    "        X=np.array([[a[position],b[position]]])\n",
    "        layer_1=layer_1_values[-position-1]\n",
    "        prev_layer_1=layer_1_values[-position-2]\n",
    "        \n",
    "        #error at output layer\n",
    "        layer_2_delta=layer_2_deltas[-position-1]\n",
    "        #error at hidden layer\n",
    "        layer_1_delta=(future_layer_1_delta.dot(wh.T)+\\\n",
    "            layer_2_delta.dot(w2.T))*sigmoid_output_to_derivative(layer_1)\n",
    "                                \n",
    "            \n",
    "        #update the weights,atleat_xd()直接将数组视为x维的数\n",
    "        w_update2+=np.atleast_2d(layer_1).T.dot(layer_2_delta)\n",
    "        w_updateh+=np.atleast_2d(prev_layer_1).T.dot(layer_1_delta)\n",
    "        w_update1+=X.T.dot(layer_1_delta)\n",
    "        \n",
    "        future_layer_1_delta=layer_1_delta\n",
    "\n",
    "    w1+=w_update1*alpha\n",
    "    w2+=w_update2*alpha\n",
    "    wh+=w_updateh*alpha\n",
    "\n",
    "    #恢复1原来的δ，也就是清零\n",
    "    w_update1*=0\n",
    "    w_update2*=0\n",
    "    w_updateh*=0\n",
    "    \n",
    "    #print out progress\n",
    "    if(j%1000==0):\n",
    "        print(\"Error:\"+str(overallError))\n",
    "        print(\"Pred:\"+str(d))\n",
    "        print(\"True:\"+str(c))\n",
    "        out =0\n",
    "        for index,x in enumerate(reversed(d)):\n",
    "            #使用reversed为了使训练方便，因为训练的输入顺序是从低位开始的，现实倒过来\n",
    "            out+=x*pow(2,index)\n",
    "        print(str(a_int)+\"+\"+str(b_int)+\"=\"+str(out))\n",
    "        print(\"---------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
