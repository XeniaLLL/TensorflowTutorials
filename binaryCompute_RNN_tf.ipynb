{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "int2binary={}\n",
    "binary_dim=8\n",
    "\n",
    "largest_num=pow(2,binary_dim)\n",
    "\n",
    "binary=np.unpackbits(\n",
    "    np.array([range(largest_num)],dtype=np.uint8).T,axis=1)\n",
    "for i in range(largest_num):\n",
    "    int2binary[i]=binary[i]\n",
    "\n",
    "def binary_generation(numbers,reverse=False):\n",
    "    '''如果reverse=True,那么训练会比较方便，输入从低位开始'''\n",
    "    x=np.array([int2binary[num] for num in numbers], dtype=np.uint8)\n",
    "    \n",
    "    if reverse:\n",
    "        x=np.fliplr(x)\n",
    "    return x\n",
    "\n",
    "def batch_generation(batch_size,largest_num):\n",
    "    '''生成batch_size大小的数进行验证或训练'''\n",
    "    n1=np.random.randint(0,largest_num//2,batch_size)\n",
    "    n2=np.random.randint(0,largest_num//2,batch_size)\n",
    "    add=n1+n2\n",
    "    \n",
    "    #int to binary\n",
    "    binary_n1=binary_generation(n1,True)\n",
    "    binary_n2=binary_generation(n2,True)\n",
    "    batch_y=binary_generation(add,True)\n",
    "    \n",
    "    #利用第三维进行深入反正合成了三维数组，\n",
    "    batch_x=np.dstack((binary_n1,binary_n2))\n",
    "    return batch_x,batch_y,n1,n2,add\n",
    "\n",
    "def binary2int(binary_array):\n",
    "    out=0\n",
    "    for index,x in enumerate(reversed(binary_array)):\n",
    "        out+=x*pow(2,index)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "lstm_size=20\n",
    "lstm_layers=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32,[None,binary_dim,2],name='input_x')\n",
    "y_=tf.placeholder(tf.float32,[None,binary_dim],name='input_y')\n",
    "\n",
    "#dropout 参数\n",
    "keep_prob=tf.placeholder(tf.float32,name='keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#搭建的lstm层（就是隐层）\n",
    "lstm=tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "'''\n",
    "    作用：构建一个cell,选择basic...的原因是目前够用了，参考的说还有其他的\n",
    "    参数：\n",
    "    num_uints:LSTM cell的units数目\n",
    "    forget_bias:float，遗忘门的偏置值\n",
    "    state_is_tuple=True,接收和返回的是state（c_state,m_state（ht)二元组；false的话，两个连成列向量\n",
    "    activation激活函数，不用多说\n",
    "    reuse：是否在现有的作用域里边重用\n",
    "'''\n",
    "\n",
    "#dropout\n",
    "drop=tf.contrib.rnn.DropoutWrapper(lstm,output_keep_prob=keep_prob)\n",
    "'''\n",
    "    作用：\n",
    "    参数:用于正则化，作用是不是不同时刻，而是同一时刻的输入输出有所舍弃\n",
    "    cell:循环网络的cell\n",
    "    in_keep_prob:使用dropout的概率，如果为1则不执行\n",
    "    output_keep_prob同理\n",
    "    state_keep_prob\n",
    "    variational_recurrent:bool, True的话，应用相同的模式进行所有timestep的run调用，设置的前提是有input_size值\n",
    "    input_size: ？？？传进来的深度required ands used if variational_recurrent = True and input_keep_prob < 1.\n",
    "    dtype:Required and used iff variational_recurrent = True.\n",
    "    seed:\n",
    "    dropout_state_filter_visitor:返回描述要丢弃的terms\n",
    "'''\n",
    "def lstm_cell():\n",
    "    return tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "cell=tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(lstm_layers)])\n",
    "'''堆叠多个cell,但是以完整地cell形式存在，每个小cell状态会保留'''\n",
    "\n",
    "#初始状态，state_size在上一个函数就已经创建好了，但是batch_size未知，自己给\n",
    "#state是cell一依次接收num_steps个输入之后产生的\n",
    "initial_state=cell.zero_state(batch_size,tf.float32)\n",
    "\n",
    "#进行forward，得到隐层输出\n",
    "#output size=[batch_size,lstm_size*binasy_dim]\n",
    "outputs,final_state=tf.nn.dynamic_rnn(cell,x,initial_state=initial_state)\n",
    "'''构建rnn的函数之一,输入不是tensors的list而是一份tensor\n",
    "    输出pair(outputs,state)\n",
    "    参数：\n",
    "    cell:\n",
    "    inputs:就是tensor\n",
    "    squence_length=None,required, 可以动态计算\n",
    "    initial_state=None\n",
    "    dtype=None\n",
    "    parallel_iterations=None\n",
    "    swap_memory=false\n",
    "    time_major=False\n",
    "    scope=None\n",
    "'''\n",
    "\n",
    "weights=tf.Variable(tf.truncated_normal([lstm_size,1],stddev=0.01))\n",
    "'''截断2*stddev以外的值'''\n",
    "biases=tf.zeros([1])\n",
    "\n",
    "# [batch_size,lstm_size*binary_dim]==>[batch_size*binary_dim,lstm_size]\n",
    "outputs=tf.reshape(outputs,[-1,lstm_size])\n",
    "#得到输出，logits大小为[batch_size*binary_size,1]\n",
    "logits=tf.sigmoid(tf.matmul(outputs,weights))\n",
    "#[batch_size*binary_dim,1]=>batch_size,binary_dim]\n",
    "predictions=tf.reshape(logits,[-1,binary_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost=tf.losses.mean_squared_error(y_,predictions)\n",
    "optimizer=tf.train.AdamOptimizer().minimize(cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:1000,Loss:0.05543878674507141\n",
      "Iter:2000,Loss:0.0016524838283658028\n",
      "[0 1 0 1 0 0 0 0]:80\n",
      "[0 1 1 0 1 1 1 1]:111\n",
      "[1 0 1 1 1 1 1 1]:191\n",
      "\n",
      "[0 0 0 0 1 1 1 0]:14\n",
      "[0 0 1 0 0 0 1 0]:34\n",
      "[0 0 1 1 0 0 0 0]:48\n",
      "\n",
      "[0 1 0 0 0 1 0 0]:68\n",
      "[0 0 0 1 0 1 1 0]:22\n",
      "[0 1 0 1 1 0 1 0]:90\n",
      "\n",
      "[0 0 0 0 0 1 0 0]:4\n",
      "[0 1 1 1 0 0 1 0]:114\n",
      "[0 1 1 1 0 1 1 0]:118\n",
      "\n",
      "[0 0 0 0 0 0 0 0]:0\n",
      "[0 0 1 1 1 0 0 1]:57\n",
      "[0 0 1 1 1 0 0 1]:57\n",
      "\n",
      "[0 1 0 0 0 1 1 1]:71\n",
      "[0 0 0 1 1 1 0 0]:28\n",
      "[0 1 1 0 0 0 1 1]:99\n",
      "\n",
      "[0 0 0 1 0 0 0 0]:16\n",
      "[0 0 1 1 1 1 1 1]:63\n",
      "[0 1 0 0 1 1 1 1]:79\n",
      "\n",
      "[0 0 1 1 1 0 0 0]:56\n",
      "[0 0 0 0 0 0 0 0]:0\n",
      "[0 0 1 1 1 0 0 0]:56\n",
      "\n",
      "[0 1 1 1 1 1 1 0]:126\n",
      "[0 1 1 0 0 1 1 1]:103\n",
      "[1 1 1 0 0 1 0 1]:229\n",
      "\n",
      "[0 1 0 1 0 1 1 1]:87\n",
      "[0 1 0 0 0 1 0 0]:68\n",
      "[1 0 0 1 1 0 1 1]:155\n",
      "\n",
      "[0 0 1 0 0 1 1 1]:39\n",
      "[0 1 0 1 0 0 1 1]:83\n",
      "[0 1 1 1 1 0 1 0]:122\n",
      "\n",
      "[0 0 0 0 0 0 1 1]:3\n",
      "[0 0 0 0 0 0 0 1]:1\n",
      "[0 0 0 0 0 1 0 0]:4\n",
      "\n",
      "[0 0 1 0 0 1 0 1]:37\n",
      "[0 0 1 0 0 1 1 0]:38\n",
      "[0 1 0 0 1 0 1 1]:75\n",
      "\n",
      "[0 1 0 1 1 0 1 0]:90\n",
      "[0 0 1 1 0 1 0 1]:53\n",
      "[1 0 0 0 1 1 1 1]:143\n",
      "\n",
      "[0 1 1 0 1 1 1 1]:111\n",
      "[0 0 0 1 0 0 1 1]:19\n",
      "[1 0 0 0 0 0 1 0]:130\n",
      "\n",
      "[0 0 0 0 0 1 1 0]:6\n",
      "[0 0 0 1 0 1 1 0]:22\n",
      "[0 0 0 1 1 1 0 0]:28\n",
      "\n",
      "[0 1 1 0 1 0 0 0]:104\n",
      "[0 0 0 1 1 0 0 1]:25\n",
      "[1 0 0 0 0 0 0 1]:129\n",
      "\n",
      "[0 1 1 0 0 0 1 0]:98\n",
      "[0 0 1 0 0 1 1 0]:38\n",
      "[1 0 0 0 1 0 0 0]:136\n",
      "\n",
      "[0 1 1 1 1 1 0 0]:124\n",
      "[0 0 0 0 1 1 0 0]:12\n",
      "[1 0 0 0 1 0 0 0]:136\n",
      "\n",
      "[0 0 0 0 1 1 0 1]:13\n",
      "[0 0 0 1 0 1 0 1]:21\n",
      "[0 0 1 0 0 0 1 0]:34\n",
      "\n",
      "[0 1 0 0 0 0 1 1]:67\n",
      "[0 0 0 0 0 0 1 0]:2\n",
      "[0 1 0 0 0 1 0 1]:69\n",
      "\n",
      "[0 0 0 0 0 0 0 1]:1\n",
      "[0 1 0 0 1 1 0 0]:76\n",
      "[0 1 0 0 1 1 0 1]:77\n",
      "\n",
      "[0 0 0 1 0 1 1 0]:22\n",
      "[0 1 1 1 0 1 1 1]:119\n",
      "[1 0 0 0 1 1 0 1]:141\n",
      "\n",
      "[0 1 1 1 0 1 1 1]:119\n",
      "[0 0 0 1 1 0 1 0]:26\n",
      "[1 0 0 1 0 0 0 1]:145\n",
      "\n",
      "[0 0 0 0 0 0 0 1]:1\n",
      "[0 0 0 0 0 0 0 1]:1\n",
      "[0 0 0 0 0 0 1 0]:2\n",
      "\n",
      "[0 0 1 1 1 1 1 1]:63\n",
      "[0 1 1 1 0 1 0 0]:116\n",
      "[1 0 1 1 0 0 1 1]:179\n",
      "\n",
      "[0 0 1 1 1 0 0 0]:56\n",
      "[0 1 1 1 0 0 0 0]:112\n",
      "[1 0 1 0 1 0 0 0]:168\n",
      "\n",
      "[0 1 0 0 0 0 0 1]:65\n",
      "[0 0 1 0 0 1 1 1]:39\n",
      "[0 1 1 0 1 0 0 0]:104\n",
      "\n",
      "[0 0 0 1 0 1 0 1]:21\n",
      "[0 0 0 0 1 1 0 0]:12\n",
      "[0 0 1 0 0 0 0 1]:33\n",
      "\n",
      "[0 0 1 1 0 0 1 1]:51\n",
      "[0 0 1 0 1 0 0 1]:41\n",
      "[0 1 0 1 1 1 0 0]:92\n",
      "\n",
      "[0 0 0 1 0 1 1 1]:23\n",
      "[0 0 1 0 0 0 1 0]:34\n",
      "[0 0 1 1 1 0 0 1]:57\n",
      "\n",
      "[0 1 1 1 0 1 1 0]:118\n",
      "[0 0 1 1 1 1 0 0]:60\n",
      "[1 0 1 1 0 0 1 0]:178\n",
      "\n",
      "[0 0 1 0 1 0 1 1]:43\n",
      "[0 0 0 0 1 0 1 1]:11\n",
      "[0 0 1 1 0 1 1 0]:54\n",
      "\n",
      "[0 0 0 1 1 1 0 0]:28\n",
      "[0 0 0 0 0 0 1 1]:3\n",
      "[0 0 0 1 1 1 1 1]:31\n",
      "\n",
      "[0 1 0 1 0 0 1 1]:83\n",
      "[0 0 0 0 0 1 0 0]:4\n",
      "[0 1 0 1 0 1 1 1]:87\n",
      "\n",
      "[0 0 1 0 1 0 1 0]:42\n",
      "[0 1 1 1 1 0 1 0]:122\n",
      "[1 0 1 0 0 1 0 0]:164\n",
      "\n",
      "[0 1 0 0 1 1 0 1]:77\n",
      "[0 1 0 0 1 1 1 0]:78\n",
      "[1 0 0 1 1 0 1 1]:155\n",
      "\n",
      "[0 0 0 1 1 0 1 1]:27\n",
      "[0 1 1 0 1 0 0 1]:105\n",
      "[1 0 0 0 0 1 0 0]:132\n",
      "\n",
      "[0 0 1 1 1 0 1 1]:59\n",
      "[0 1 1 0 1 0 1 1]:107\n",
      "[1 0 1 0 0 1 1 0]:166\n",
      "\n",
      "[0 0 1 0 0 1 0 1]:37\n",
      "[0 1 0 0 0 1 0 0]:68\n",
      "[0 1 1 0 1 0 0 1]:105\n",
      "\n",
      "[0 1 1 1 0 1 1 1]:119\n",
      "[0 1 1 1 1 1 0 1]:125\n",
      "[1 1 1 1 0 1 0 0]:244\n",
      "\n",
      "[0 0 0 1 0 0 1 0]:18\n",
      "[0 0 0 0 1 1 0 0]:12\n",
      "[0 0 0 1 1 1 1 0]:30\n",
      "\n",
      "[0 1 1 0 1 0 0 1]:105\n",
      "[0 1 1 0 1 1 0 1]:109\n",
      "[1 1 0 1 0 1 1 0]:214\n",
      "\n",
      "[0 0 0 1 1 1 1 0]:30\n",
      "[0 1 0 1 0 0 1 1]:83\n",
      "[0 1 1 1 0 0 0 1]:113\n",
      "\n",
      "[0 1 0 0 1 1 0 1]:77\n",
      "[0 0 0 1 1 0 1 0]:26\n",
      "[0 1 1 0 0 1 1 1]:103\n",
      "\n",
      "[0 0 0 1 1 1 0 0]:28\n",
      "[0 1 1 1 0 1 0 0]:116\n",
      "[1 0 0 1 0 0 0 0]:144\n",
      "\n",
      "[0 1 1 0 0 0 0 0]:96\n",
      "[0 0 1 0 1 1 1 0]:46\n",
      "[1 0 0 0 1 1 1 0]:142\n",
      "\n",
      "[0 1 0 1 0 1 0 1]:85\n",
      "[0 1 0 1 0 0 0 1]:81\n",
      "[1 0 1 0 0 1 1 0]:166\n",
      "\n",
      "[0 1 1 1 0 0 0 0]:112\n",
      "[0 0 0 0 0 1 0 0]:4\n",
      "[0 1 1 1 0 1 0 0]:116\n",
      "\n",
      "[0 0 1 0 0 1 1 1]:39\n",
      "[0 1 0 0 1 0 0 1]:73\n",
      "[0 1 1 1 0 0 0 0]:112\n",
      "\n",
      "[0 0 0 0 0 0 0 1]:1\n",
      "[0 1 1 0 1 1 1 0]:110\n",
      "[0 1 1 0 1 1 1 1]:111\n",
      "\n",
      "[0 0 1 0 0 1 1 1]:39\n",
      "[0 1 1 1 0 0 0 0]:112\n",
      "[1 0 0 1 0 1 1 1]:151\n",
      "\n",
      "[0 0 1 0 0 1 1 1]:39\n",
      "[0 0 1 1 1 1 0 1]:61\n",
      "[0 1 1 0 0 1 0 0]:100\n",
      "\n",
      "[0 1 0 0 1 0 1 0]:74\n",
      "[0 0 0 1 1 0 1 0]:26\n",
      "[0 1 1 0 0 1 0 0]:100\n",
      "\n",
      "[0 0 1 1 0 1 1 1]:55\n",
      "[0 1 0 1 0 1 0 0]:84\n",
      "[1 0 0 0 1 0 1 1]:139\n",
      "\n",
      "[0 0 1 1 0 1 1 1]:55\n",
      "[0 0 1 0 0 1 0 1]:37\n",
      "[0 1 0 1 1 1 0 0]:92\n",
      "\n",
      "[0 1 0 0 1 0 1 1]:75\n",
      "[0 0 0 1 1 0 1 1]:27\n",
      "[0 1 1 0 0 1 1 0]:102\n",
      "\n",
      "[0 0 0 1 0 0 1 1]:19\n",
      "[0 0 0 1 1 1 0 1]:29\n",
      "[0 0 1 1 0 0 0 0]:48\n",
      "\n",
      "[0 1 0 1 0 0 1 1]:83\n",
      "[0 0 0 0 1 1 1 0]:14\n",
      "[0 1 1 0 0 0 0 1]:97\n",
      "\n",
      "[0 0 0 0 1 0 0 1]:9\n",
      "[0 1 1 1 0 0 1 1]:115\n",
      "[0 1 1 1 1 1 0 0]:124\n",
      "\n",
      "[0 1 1 1 1 1 1 0]:126\n",
      "[0 1 1 1 1 0 1 0]:122\n",
      "[1 1 1 1 1 0 0 0]:248\n",
      "\n",
      "[0 0 0 1 1 0 1 0]:26\n",
      "[0 0 0 0 1 0 1 1]:11\n",
      "[0 0 1 0 0 1 0 1]:37\n",
      "\n",
      "[0 1 0 1 0 0 0 1]:81\n",
      "[0 0 1 0 1 0 1 1]:43\n",
      "[0 1 1 1 1 1 0 0]:124\n",
      "\n",
      "[0 0 0 0 1 0 1 1]:11\n",
      "[0 1 1 0 0 0 0 0]:96\n",
      "[0 1 1 0 1 0 1 1]:107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "steps=2000\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    iteration=1\n",
    "    for i in range(steps):\n",
    "        input_x,input_y,_,_,_=batch_generation(batch_size,largest_num)\n",
    "        _,loss=sess.run([optimizer,cost],feed_dict={x:input_x,y_:input_y,keep_prob:0.5})\n",
    "        if iteration%1000==0:\n",
    "            print(\"Iter:{},Loss:{}\".format(iteration,loss))\n",
    "        iteration+=1\n",
    "        \n",
    "    #testing\n",
    "    val_x,val_y,n1,n2,add=batch_generation(batch_size,largest_num)\n",
    "    result=sess.run(predictions,feed_dict={x:val_x,y_:val_y,keep_prob:1.0})\n",
    "    result=np.fliplr(np.round(result))\n",
    "    result=result.astype(np.int32)\n",
    "    \n",
    "    for b_x,b_p,a,b,add in zip(np.fliplr(val_x),result,n1,n2,add):\n",
    "        '''打包成元组，返回对象'''\n",
    "        print('{}:{}'.format(b_x[:,0],a))\n",
    "        print('{}:{}'.format(b_x[:,1],b))\n",
    "        print('{}:{}\\n'.format(b_p,binary2int(b_p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
